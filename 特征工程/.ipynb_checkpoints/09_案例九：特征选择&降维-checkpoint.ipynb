{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 2, 0, 3],\n",
    "    [0, 1, 4, 3],\n",
    "    [0.1, 1, 1, 3]\n",
    "], dtype=np.float32)\n",
    "Y = np.array([1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarianceThreshold(threshold=0.1)\n",
      "各个特征属性的方差为:\n",
      "[  2.22222229e-03   2.22222222e-01   2.88888889e+00   0.00000000e+00]\n",
      "-----------------\n",
      "[[ 2.  0.]\n",
      " [ 1.  4.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# 基于方差选择最优的特征属性\n",
    "variance = VarianceThreshold(threshold=0.1)\n",
    "print(variance)\n",
    "variance.fit(X)\n",
    "print(\"各个特征属性的方差为:\")\n",
    "print(variance.variances_)\n",
    "print('-----------------')\n",
    "print(variance.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function f_regression at 0x000002045A8E2268>)\n",
      "------------\n",
      "[  0.33333333   0.33333333  16.33333333          nan]\n",
      "------------\n",
      "[[ 2.  0.]\n",
      " [ 1.  4.]\n",
      " [ 1.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "sk1 = SelectKBest(f_regression, k=2)\n",
    "sk1.fit(X, Y)\n",
    "print(sk1)\n",
    "print('------------')\n",
    "print(sk1.scores_)\n",
    "print('------------')\n",
    "print(sk1.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function chi2 at 0x000002045A8E21E0>)\n",
      "[ 0.05   0.125  4.9    0.   ]\n",
      "[[ 2.  0.]\n",
      " [ 1.  4.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# 使用chi2的时候要求特征属性的取值为非负数\n",
    "sk2 = SelectKBest(chi2, k=2)\n",
    "sk2.fit(X, Y)\n",
    "print(sk2)\n",
    "print(sk2.scores_)\n",
    "print(sk2.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False]\n",
      "2\n",
      "[2 1 1 3]\n",
      "[[ 2.  0.]\n",
      " [ 1.  4.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# 基于特征消去法做的特征选择\n",
    "estimator = SVR(kernel='linear')\n",
    "selector = RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(X, Y)\n",
    "print(selector.support_)\n",
    "print(selector.n_features_)\n",
    "print(selector.ranking_)\n",
    "print(selector.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1]\n",
      " [ 4.9]\n",
      " [-6.2]\n",
      " [-5.9]]\n",
      "系数:\n",
      "[[-0.03417754  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X2 = np.array([\n",
    "    [ 5.1,  3.5,  1.4,  0.2],\n",
    "    [ 4.9,  3. ,  1.4,  0.2],\n",
    "    [ -6.2,  0.4,  5.4,  2.3],\n",
    "    [ -5.9,  0. ,  5.1,  1.8]\n",
    "], dtype=np.float64)\n",
    "Y2 = np.array([0, 0, 2, 2])\n",
    "estimator = LogisticRegression(penalty='l1', C=0.1)\n",
    "sfm = SelectFromModel(estimator)\n",
    "sfm.fit(X2, Y2)\n",
    "print(sfm.transform(X2))\n",
    "print(\"系数:\")\n",
    "print(sfm.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  0.2]\n",
      " [ 4.9  3.   0.2]\n",
      " [-6.2  0.4  2.3]\n",
      " [-5.9  0.   1.8]]\n",
      "权重因子:\n",
      "[ 0.18  0.23  0.12  0.21]\n"
     ]
    }
   ],
   "source": [
    "X2 = np.array([\n",
    "    [ 5.1,  3.5,  1.4,  0.2],\n",
    "    [ 4.9,  3. ,  1.4,  0.2],\n",
    "    [ -6.2,  0.4,  5.4,  2.3],\n",
    "    [ -5.9,  0. ,  5.1,  1.8]\n",
    "], dtype=np.float64)\n",
    "Y2 = np.array([0, 0, 2, 2])\n",
    "estimator = GradientBoostingClassifier(random_state=14)\n",
    "# 如果基础模型是GBDT，那么一般阈值最好选择0，原因：可以认为当大于0的特征属性是具有影响y值的作用的，所以针对这些特征我们保留\n",
    "# 如果删除了，重要性大于0的特征的话，那么相当于后续的模型训练过程中，存在部分判断能力的特征被删除了，那么模型效果可能会差一点\n",
    "sfm = SelectFromModel(estimator,threshold=0.15)\n",
    "sfm.fit(X2, Y2)\n",
    "print(sfm.transform(X2))\n",
    "print(\"权重因子:\")\n",
    "print(sfm.estimator_.feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.525   1.725   3.325   1.125   1.825  12.775]\n",
      "[[ 0.02038178 -0.01698103 -0.01350052 -0.0149724   0.03184796 -0.99893718]\n",
      " [ 0.9024592   0.25030511 -0.31422084 -0.15092666 -0.03185873  0.01965141]\n",
      " [-0.08872116 -0.06952185 -0.06858116 -0.3074396  -0.94204108 -0.02512755]]\n",
      "[[-0.98788492  1.06095297  0.94787245]\n",
      " [ 1.0554112   0.93712001 -1.00394885]\n",
      " [-1.01046952 -0.99473186 -0.99471598]\n",
      " [ 0.94294324 -1.00334112  1.05079239]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X2 = np.array([\n",
    "    [ 5.1,  3.5,  1.4,  0.2, 1, 23],\n",
    "    [ 4.9,  3. ,  1.4,  0.2, 2.3, 2.1],\n",
    "    [ -6.2,  0.4,  5.4,  2.3, 2, 23],\n",
    "    [ -5.9,  0. ,  5.1,  1.8, 2, 3]\n",
    "], dtype=np.float64)\n",
    "# n_components: 给定降低到多少维度，但是要求该值必须小于等于样本数目/特征数目，如果给定的值大于，那么会选择样本数目/特征数目中最小的那个作为最终的特征数目\n",
    "# whiten：是否做一个白化的操作，在PCA的基础上，对于特征属性是否做一个标准化\n",
    "pca = PCA(n_components=3,whiten=True)\n",
    "pca.fit(X2)\n",
    "print(pca.mean_)\n",
    "print(pca.components_)\n",
    "print(pca.transform(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.2688434  -0.38911349]\n",
      " [-1.25507558 -1.78088569]\n",
      " [ 5.26064254 -0.49688862]\n",
      " [ 6.34385833  1.16134391]\n",
      " [-4.05800618  3.58297801]\n",
      " [-3.02257571 -2.07743411]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = np.array([\n",
    "    [-1, -1, 3, 1], \n",
    "    [-2, -1, 2, 4], \n",
    "    [-3, -2, 4, 5], \n",
    "    [1, 1, 5, 4], \n",
    "    [2, 1, 6, -5], \n",
    "    [3, 2, 1, 5]])\n",
    "y = np.array([1, 1, 2, 2, 0, 1])\n",
    "# n_components：给定降低到多少维度，要求给定的这个值和y的取值数量有关，不能超过n_class-1\n",
    "clf = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf.fit(X, y)\n",
    "print(clf.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
