{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#引入包\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#加载数据，加载的在input_data.py里面\n",
    "mnist = input_data.read_data_sets('data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READ\n"
     ]
    }
   ],
   "source": [
    "# NETWORK TOPOLOGIES\n",
    "n_hidden_1 = 256 #第一个隐藏层的神经元数\n",
    "n_hidden_2 = 128 #第二个隐藏层的神经元数\n",
    "n_input    = 784 #输入的像素 28*28\n",
    "n_classes  = 10  #输出的label[0，0,0,0,0,1,0,0,0,0] one_hot\n",
    "# INPUTS AND OUTPUTS\n",
    "x=tf.placeholder(\"float\",[None,n_input],name='x')\n",
    "y=tf.placeholder(\"float\",[None,n_classes],name='y')\n",
    "\n",
    "#神经网络，设立2个隐藏，填充数据\n",
    "#标准偏差\n",
    "stddev=0.1\n",
    "#权重\n",
    "weights={\n",
    "    \"w1\":tf.Variable(tf.random_normal([n_input,n_hidden_1],stddev=stddev)),\n",
    "    \"w2\":tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2],stddev=stddev)),\n",
    "    \"out\":tf.Variable(tf.random_normal([n_hidden_2,n_classes],stddev=stddev))\n",
    "}\n",
    "#偏置值\n",
    "biases={\n",
    "    \"b1\":tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\":tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"out\":tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "print (\"NETWORK READ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#s激活函数，进行数据的操作 （BP算法）\n",
    "def multilayer_perceotron(_X, _weights, _biases):\n",
    "    #sigmoid激活函数\n",
    "    layer_1=tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['w1']),_biases['b1']))#每次wx+b之后经过sigmoid函数激活\n",
    "    layer_2=tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights['w2']),_biases['b2']))\n",
    "    return (tf.matmul(layer_2, _weights['out'])+_biases['out'])#返回的是10个输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "pred=multilayer_perceotron(x,weights,biases)\n",
    "\n",
    "#损失函数 softmax_cross_entropy_with_logits中0.x版本和1.x不同的是1.x要加logits和labels\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "#执行GradientDescentOptimizer梯度下降以及minimize优化\n",
    "optm=tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n",
    "#如果相等返回true，不等返回flase\n",
    "corr=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "#把true转为1，false为0，再相加，计算总的（正确率）\n",
    "accr=tf.reduce_mean(tf.cast(corr,\"float\"))\n",
    "\n",
    "#初始化\n",
    "init=tf.global_variables_initializer()\n",
    "print (\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/020 cost: 2.280538216\n",
      "TRAIN ACCURACY: 0.100\n",
      "TEST ACCURACY: 0.157\n",
      "Epoch: 007/020 cost: 2.247892685\n",
      "TRAIN ACCURACY: 0.240\n",
      "TEST ACCURACY: 0.274\n",
      "Epoch: 011/020 cost: 2.212539887\n",
      "TRAIN ACCURACY: 0.460\n",
      "TEST ACCURACY: 0.399\n",
      "Epoch: 015/020 cost: 2.172422694\n",
      "TRAIN ACCURACY: 0.440\n",
      "TEST ACCURACY: 0.468\n",
      "Epoch: 019/020 cost: 2.125489607\n",
      "TRAIN ACCURACY: 0.520\n",
      "TEST ACCURACY: 0.520\n",
      "Epoch: 023/020 cost: 2.069665157\n",
      "TRAIN ACCURACY: 0.500\n",
      "TEST ACCURACY: 0.558\n",
      "Epoch: 027/020 cost: 2.003387713\n",
      "TRAIN ACCURACY: 0.590\n",
      "TEST ACCURACY: 0.608\n",
      "Epoch: 031/020 cost: 1.925586604\n",
      "TRAIN ACCURACY: 0.640\n",
      "TEST ACCURACY: 0.629\n",
      "Epoch: 035/020 cost: 1.836715375\n",
      "TRAIN ACCURACY: 0.640\n",
      "TEST ACCURACY: 0.652\n",
      "Epoch: 039/020 cost: 1.738751326\n",
      "TRAIN ACCURACY: 0.680\n",
      "TEST ACCURACY: 0.672\n",
      "Epoch: 043/020 cost: 1.635182406\n",
      "TRAIN ACCURACY: 0.670\n",
      "TEST ACCURACY: 0.692\n",
      "Epoch: 047/020 cost: 1.530344173\n",
      "TRAIN ACCURACY: 0.710\n",
      "TEST ACCURACY: 0.712\n",
      "Epoch: 051/020 cost: 1.428311844\n",
      "TRAIN ACCURACY: 0.720\n",
      "TEST ACCURACY: 0.730\n",
      "Epoch: 055/020 cost: 1.332080117\n",
      "TRAIN ACCURACY: 0.700\n",
      "TEST ACCURACY: 0.744\n",
      "Epoch: 059/020 cost: 1.243432468\n",
      "TRAIN ACCURACY: 0.720\n",
      "TEST ACCURACY: 0.755\n",
      "Epoch: 063/020 cost: 1.163165643\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.772\n",
      "Epoch: 067/020 cost: 1.091236481\n",
      "TRAIN ACCURACY: 0.710\n",
      "TEST ACCURACY: 0.781\n",
      "Epoch: 071/020 cost: 1.027242878\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.791\n",
      "Epoch: 075/020 cost: 0.970496989\n",
      "TRAIN ACCURACY: 0.780\n",
      "TEST ACCURACY: 0.799\n",
      "Epoch: 079/020 cost: 0.920166372\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.807\n",
      "Epoch: 083/020 cost: 0.875542051\n",
      "TRAIN ACCURACY: 0.760\n",
      "TEST ACCURACY: 0.813\n",
      "Epoch: 087/020 cost: 0.835825862\n",
      "TRAIN ACCURACY: 0.760\n",
      "TEST ACCURACY: 0.820\n",
      "Epoch: 091/020 cost: 0.800371757\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.826\n",
      "Epoch: 095/020 cost: 0.768597215\n",
      "TRAIN ACCURACY: 0.770\n",
      "TEST ACCURACY: 0.831\n",
      "Epoch: 099/020 cost: 0.740011434\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.836\n",
      "Epoch: 103/020 cost: 0.714179598\n",
      "TRAIN ACCURACY: 0.840\n",
      "TEST ACCURACY: 0.840\n",
      "Epoch: 107/020 cost: 0.690746916\n",
      "TRAIN ACCURACY: 0.890\n",
      "TEST ACCURACY: 0.845\n",
      "Epoch: 111/020 cost: 0.669387897\n",
      "TRAIN ACCURACY: 0.780\n",
      "TEST ACCURACY: 0.847\n",
      "Epoch: 115/020 cost: 0.649879681\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.850\n",
      "Epoch: 119/020 cost: 0.631948688\n",
      "TRAIN ACCURACY: 0.840\n",
      "TEST ACCURACY: 0.854\n",
      "Epoch: 123/020 cost: 0.615453378\n",
      "TRAIN ACCURACY: 0.820\n",
      "TEST ACCURACY: 0.857\n",
      "Epoch: 127/020 cost: 0.600208266\n",
      "TRAIN ACCURACY: 0.770\n",
      "TEST ACCURACY: 0.859\n",
      "Epoch: 131/020 cost: 0.586084046\n",
      "TRAIN ACCURACY: 0.890\n",
      "TEST ACCURACY: 0.862\n",
      "Epoch: 135/020 cost: 0.572951419\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.864\n",
      "Epoch: 139/020 cost: 0.560734061\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.867\n",
      "Epoch: 143/020 cost: 0.549320115\n",
      "TRAIN ACCURACY: 0.890\n",
      "TEST ACCURACY: 0.869\n",
      "Epoch: 147/020 cost: 0.538620306\n",
      "TRAIN ACCURACY: 0.740\n",
      "TEST ACCURACY: 0.872\n",
      "Epoch: 151/020 cost: 0.528623333\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.873\n",
      "Epoch: 155/020 cost: 0.519215852\n",
      "TRAIN ACCURACY: 0.890\n",
      "TEST ACCURACY: 0.873\n",
      "Epoch: 159/020 cost: 0.510355304\n",
      "TRAIN ACCURACY: 0.880\n",
      "TEST ACCURACY: 0.874\n",
      "Epoch: 163/020 cost: 0.502017722\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.876\n",
      "Epoch: 167/020 cost: 0.494137333\n",
      "TRAIN ACCURACY: 0.880\n",
      "TEST ACCURACY: 0.878\n",
      "Epoch: 171/020 cost: 0.486707979\n",
      "TRAIN ACCURACY: 0.900\n",
      "TEST ACCURACY: 0.879\n",
      "Epoch: 175/020 cost: 0.479674230\n",
      "TRAIN ACCURACY: 0.830\n",
      "TEST ACCURACY: 0.880\n",
      "Epoch: 179/020 cost: 0.473013612\n",
      "TRAIN ACCURACY: 0.800\n",
      "TEST ACCURACY: 0.882\n",
      "Epoch: 183/020 cost: 0.466690320\n",
      "TRAIN ACCURACY: 0.860\n",
      "TEST ACCURACY: 0.883\n",
      "Epoch: 187/020 cost: 0.460678255\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.885\n",
      "Epoch: 191/020 cost: 0.454975071\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.886\n",
      "Epoch: 195/020 cost: 0.449558220\n",
      "TRAIN ACCURACY: 0.900\n",
      "TEST ACCURACY: 0.887\n",
      "Epoch: 199/020 cost: 0.444394266\n",
      "TRAIN ACCURACY: 0.920\n",
      "TEST ACCURACY: 0.888\n",
      "Epoch: 203/020 cost: 0.439471302\n",
      "TRAIN ACCURACY: 0.880\n",
      "TEST ACCURACY: 0.889\n",
      "Epoch: 207/020 cost: 0.434779099\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.890\n",
      "Epoch: 211/020 cost: 0.430286189\n",
      "TRAIN ACCURACY: 0.930\n",
      "TEST ACCURACY: 0.890\n",
      "Epoch: 215/020 cost: 0.426008398\n",
      "TRAIN ACCURACY: 0.920\n",
      "TEST ACCURACY: 0.891\n",
      "Epoch: 219/020 cost: 0.421906748\n",
      "TRAIN ACCURACY: 0.880\n",
      "TEST ACCURACY: 0.891\n",
      "Epoch: 223/020 cost: 0.417981315\n",
      "TRAIN ACCURACY: 0.910\n",
      "TEST ACCURACY: 0.892\n",
      "Epoch: 227/020 cost: 0.414209946\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.892\n",
      "Epoch: 231/020 cost: 0.410608870\n",
      "TRAIN ACCURACY: 0.920\n",
      "TEST ACCURACY: 0.894\n",
      "Epoch: 235/020 cost: 0.407138212\n",
      "TRAIN ACCURACY: 0.840\n",
      "TEST ACCURACY: 0.895\n",
      "Epoch: 239/020 cost: 0.403815224\n",
      "TRAIN ACCURACY: 0.910\n",
      "TEST ACCURACY: 0.896\n",
      "Epoch: 243/020 cost: 0.400615595\n",
      "TRAIN ACCURACY: 0.910\n",
      "TEST ACCURACY: 0.897\n",
      "Epoch: 247/020 cost: 0.397525106\n",
      "TRAIN ACCURACY: 0.900\n",
      "TEST ACCURACY: 0.897\n",
      "Epoch: 251/020 cost: 0.394559823\n",
      "TRAIN ACCURACY: 0.930\n",
      "TEST ACCURACY: 0.897\n",
      "Epoch: 255/020 cost: 0.391707393\n",
      "TRAIN ACCURACY: 0.880\n",
      "TEST ACCURACY: 0.898\n",
      "Epoch: 259/020 cost: 0.388941828\n",
      "TRAIN ACCURACY: 0.910\n",
      "TEST ACCURACY: 0.899\n",
      "Epoch: 263/020 cost: 0.386281116\n",
      "TRAIN ACCURACY: 0.870\n",
      "TEST ACCURACY: 0.899\n",
      "Epoch: 267/020 cost: 0.383701784\n",
      "TRAIN ACCURACY: 0.850\n",
      "TEST ACCURACY: 0.900\n",
      "Epoch: 271/020 cost: 0.381211890\n",
      "TRAIN ACCURACY: 0.930\n",
      "TEST ACCURACY: 0.900\n",
      "Epoch: 275/020 cost: 0.378806392\n",
      "TRAIN ACCURACY: 0.860\n",
      "TEST ACCURACY: 0.900\n",
      "Epoch: 279/020 cost: 0.376477849\n",
      "TRAIN ACCURACY: 0.910\n",
      "TEST ACCURACY: 0.900\n",
      "OPTIMIZATION FINISHED\n"
     ]
    }
   ],
   "source": [
    "#执行模型的训练\n",
    "training_epochs = 100#迭代的次数\n",
    "batch_size      = 100#每次处理的图片数\n",
    "display_step    = 4#每次次打印一次\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# OPTIMIZE\n",
    "# 模型保存，持久化\n",
    "saver=tf.train.Saver()\n",
    "epoch=0\n",
    "#for epoch in range(training_epochs):\n",
    "while True:\n",
    "    avg_cost = 0.   #平均误差\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # ITERATION  训练集循环次数确定\n",
    "    for i in range(total_batch):\n",
    "        #去除x和y的值\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)\n",
    "    #重新计算平均损失\n",
    "    avg_cost = avg_cost / total_batch\n",
    "    # DISPLAY  显示误差率和训练集的正确率以此测试集的正确率\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "        feeds = {x: mnist.test.images, y: mnist.test.labels}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TEST ACCURACY: %.3f\" % (test_acc))\n",
    "        #saver.save(sess, './mn', epoch)\n",
    "        if train_acc>0.9 and test_acc>0.9:\n",
    "            saver.save(sess, './mn', epoch)\n",
    "            break\n",
    "    epoch+=1\n",
    "print (\"OPTIMIZATION FINISHED\")\n",
    "writer = tf.summary.FileWriter(r\"C:\\Users\\ibf\\Documents\\code\\tf\",tf.get_default_graph())\n",
    "writer.close()\n",
    "#最后的损失函数下降的不是很多，正确率也不高，需要加大迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
