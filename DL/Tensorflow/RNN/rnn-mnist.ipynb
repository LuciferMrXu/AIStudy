{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 输入数据\n",
    "mnist=read_data_sets('/data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义网络的超参数\n",
    "learning_rate=1e-3 #学习率\n",
    "training_iters=20000 #训练的数据量\n",
    "# 在训练和测试的时候，我们想要用 不同的数值，所以batch_size 定义为占位符\n",
    "batch_size=tf.placeholder(tf.int32,[])\n",
    "#batch_size=128 #每次训练多少数据\n",
    "display_step=10  #每多少次显示一下当前状态\n",
    "\n",
    "\n",
    "#每个时刻输入的特征为28维度，就是每个时刻输入一行，一行有28个元素\n",
    "input_size=28\n",
    "# 时序持续输入长度为28，即每次做一个预测，需要输入28行\n",
    "time_step_size=28\n",
    "# 每个隐含层的节点数\n",
    "hidden_size=256\n",
    "# LSTM_Layer的层数\n",
    "layer_num=2\n",
    "# 最后输出的分类类别数\n",
    "class_num=10\n",
    "# 输入的维度\n",
    "n_input=784\n",
    "#dropout\n",
    "dropout=0.75\n",
    "#设定数据占位符\n",
    "x=tf.placeholder(tf.float32,[None,n_input])\n",
    "y=tf.placeholder(tf.float32,[None,class_num])\n",
    "keep_prob=tf.placeholder(tf.float32,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#搭建LSTM模型\n",
    "# 1.RNN的输入执行reshape。shape=(batch_size,time_step_size,input_size)\n",
    "X=tf.reshape(x,[-1,time_step_size,input_size])\n",
    "# 定义LSEM\n",
    "def lstm_cell():\n",
    "    # 2. 定义一层的LSTM_Cell，只需要设定hidden_size，他会自动匹配输入的X的维度\n",
    "    cell=rnn.BasicLSTMCell(num_units=hidden_size,forget_bias=1.0,state_is_tuple=True)\n",
    "    # 3.增加drop layer，一般只设置output_keep_prob\n",
    "    return rnn.DropoutWrapper(cell=cell,input_keep_prob=1.0,output_keep_prob=keep_prob)\n",
    "# 4.调用MultiRNNCell来实现多层LSTM\n",
    "mlstm_cell=rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)],state_is_tuple=True)\n",
    "# 5.用零来初始化state\n",
    "init_state=mlstm_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "# 6.(1)方法一，调用dynamic_rnn来运行构建的网络\n",
    "# time_major为False，表示output_shape=[batch_size,time_step_size,hidden_size]\n",
    "# state_shape=[layer_num,2,batch_size,hidden_size]\n",
    "\n",
    "# outputs,state=tf.nn.dynamic_rnn(mlstm_cell,inputs=X,initial_state=init_state,time_major=False)\n",
    "# h_state=outputs[:,-1,:] \n",
    "# 或者 \n",
    "#h_stat=state[-1][1]\n",
    "#（2）方法二，按照时间展开计算\n",
    "outputs = list()\n",
    "state = init_state\n",
    "with tf.variable_scope('RNN'):\n",
    "    for timestep in range(time_step_size):\n",
    "        if timestep > 0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        # 这里的state保存了每一层 LSTM 的状态\n",
    "        (cell_output, state) = mlstm_cell(X[:, timestep, :],state)\n",
    "        outputs.append(cell_output)\n",
    "h_state = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7.设置loss function和优化器\n",
    "# softmax的连接权重矩阵和偏置\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=0.1), dtype=tf.float32)\n",
    "bias = tf.Variable(tf.constant(0.1,shape=[class_num]), dtype=tf.float32)\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)\n",
    "\n",
    "# 损失和评估\n",
    "cross=-tf.reduce_mean(y*tf.log(y_pre))\n",
    "train_op=tf.train.AdamOptimizer(learning_rate).minimize(cross)\n",
    "\n",
    "correct_pred=tf.equal(tf.argmax(y_pre,1),tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(correct_pred,'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(training_iters):\n",
    "    _batch_size = 5\n",
    "    batch=mnist.train.next_batch(_batch_size)\n",
    "    if (i+1)*display_step==0:\n",
    "        train_accuracy = sess.run(acc, feed_dict={\n",
    "            x:batch[0], y: batch[1], keep_prob: 1.0, batch_size: _batch_size})\n",
    "        print('Acc:%f'%(train_accuracy))\n",
    "    sess.run(train_op, feed_dict={x: batch[0], y: batch[1], keep_prob: dropout, batch_size: _batch_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 可视化看看lstm怎么做分类\n",
    "import matplotlib.pyplot as plt\n",
    "X4=mnist.train.images[4]\n",
    "print(mnist.train.labels[4])\n",
    "img4=X4.reshape([28,28])\n",
    "plt.imshow(img4,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# 查看分类执行的过程\n",
    "X4.shape=[-1,784]\n",
    "y_batch=mnist.train.labels[4]\n",
    "y_batch.shape=[-1,class_num]\n",
    "X4_oupputs=np.array(session.run(outputs,feed_dict={X:X4,y:y_batch,keep_prob:1.0}))\n",
    "print(X4_oupputs.shape)\n",
    "X4_outputs.shape=[28,hidden_size]\n",
    "h_W=sess.run(W,feed_dict={X:X4,y:y_batch,keep_prob:1.0})\n",
    "h_bias=sess.run(W,feed_dict={X:X4,y:y_batch,keep_prob:1.0})\n",
    "h_bias.shape=[-1,10]\n",
    "\n",
    "# 显示output\n",
    "bar_index=range(class_num)\n",
    "for i in range(X4_outputs.shpae[0]):\n",
    "    plt.subplot(7,4,i+1)\n",
    "    X3_h_state=X4_outputs[i,:].reshape([-1,hidden_size])\n",
    "    pro=sess.run(tf.nn.softmax(X3_h_state,h_W),h_bias)\n",
    "    plt.bar(bar_index,pro[0],width=0.2,align='center')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
