{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_dic = {}\n",
    "B_dic = {}\n",
    "Count_dic = {}\n",
    "Pi_dic = {}\n",
    "word_set = set()\n",
    "state_list = ['B','M','E','S']\n",
    "line_num = -1\n",
    "\n",
    "INPUT_DATA = \"trainCorpus.txt_utf8\" # trainCorpus.txt_utf8'为人民日报已经人工分词的预料，29万多条句子\n",
    "PROB_START = \"trainHMM\\prob_start.py\"   #初始状态概率\n",
    "PROB_EMIT = \"trainHMM\\prob_emit.py\"     #发射概率\n",
    "PROB_TRANS = \"trainHMM\\prob_trans.py\" # 转移概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init():  #初始化字典\n",
    "    for state in state_list:\n",
    "        A_dic[state] = {}\n",
    "        for state1 in state_list:\n",
    "            A_dic[state][state1] = 0.0\n",
    "    for state in state_list:\n",
    "        Pi_dic[state] = 0.0\n",
    "        B_dic[state] = {}\n",
    "        Count_dic[state] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getList(input_str):  #输入词语，输出状态\n",
    "    outpout_str = []\n",
    "    if len(input_str) == 1:\n",
    "        outpout_str.append('S')\n",
    "    elif len(input_str) == 2:\n",
    "        outpout_str = ['B','E']\n",
    "    else:\n",
    "        M_num = len(input_str) -2\n",
    "        M_list = ['M'] * M_num\n",
    "        outpout_str.append('B')\n",
    "        outpout_str.extend(M_list)  #把M_list中的'M'分别添加进去\n",
    "        outpout_str.append('E')\n",
    "    return outpout_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Output():   #输出模型的三个参数：初始概率+转移概率+发射概率\n",
    "    start_fp = open(PROB_START,'w')\n",
    "    emit_fp = open(PROB_EMIT,'w',encoding='utf-8')\n",
    "    trans_fp = open(PROB_TRANS,'w')\n",
    "    print (\"len(word_set) = %s \" % (len(word_set)))\n",
    "\n",
    "    for key in Pi_dic:           #状态的初始概率\n",
    "        Pi_dic[key] = Pi_dic[key] * 1.0 / line_num\n",
    "    #print >>start_fp,Pi_dic\n",
    "    start_fp.write(json.dumps(Pi_dic,ensure_ascii=False))\n",
    "    for key in A_dic:            #状态转移概率\n",
    "        for key1 in A_dic[key]:\n",
    "            A_dic[key][key1] = A_dic[key][key1] / Count_dic[key]\n",
    "    #print >>trans_fp,A_dic\n",
    "    trans_fp.write(json.dumps(A_dic,ensure_ascii=False))\n",
    "    for key in B_dic:            #发射概率(状态->词语的条件概率)\n",
    "        for word in B_dic[key]:\n",
    "            B_dic[key][word] = B_dic[key][word] / Count_dic[key]\n",
    "    #print >>emit_fp,B_dic\n",
    "    emit_fp.write(json.dumps(B_dic,ensure_ascii=False))\n",
    "    start_fp.close()\n",
    "    emit_fp.close()\n",
    "    trans_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    ifp = open(INPUT_DATA,encoding='utf-8')\n",
    "    init()\n",
    "    global word_set   #初始是set()\n",
    "    global line_num   #初始是-1\n",
    "    for line in ifp:\n",
    "        line_num += 1\n",
    "        if line_num % 10000 == 0:\n",
    "            print (line_num)\n",
    "\n",
    "        line = line.strip()\n",
    "        if not line:continue\n",
    "        #Windows系统的txt文件在使用utf-8编码保存时会默认\n",
    "        #在文件开头插入三个不可见字符，称为BOM头，这个BOM头在python的codecs\n",
    "        #库中已经定义为常量。Windows根据BOM头来判断txt文件是否为utf-8编码，\n",
    "        #所以在读取文件时必须将BOM头去除或者忽略，否则python在decode和encode时会出现错误。\n",
    "        \n",
    "\n",
    "\n",
    "        word_list = []\n",
    "        for i in range(len(line)):\n",
    "            if line[i] == \" \":continue\n",
    "            word_list.append(line[i])\n",
    "        word_set = word_set | set(word_list)   #训练预料库中所有字的集合\n",
    "\n",
    "\n",
    "        lineArr = line.split(\" \")\n",
    "        line_state = []\n",
    "        for item in lineArr:\n",
    "            line_state.extend(getList(item))   #一句话对应一行连续的状态\n",
    "        if len(word_list) != len(line_state):\n",
    "            print >> sys.stderr,\"[line_num = %d][line = %s]\" % (line_num, line.endoce(\"utf-8\",'ignore'))\n",
    "        else:\n",
    "            for i in range(len(line_state)):\n",
    "                if i == 0:\n",
    "                    Pi_dic[line_state[0]] += 1      #Pi_dic记录句子第一个字的状态，用于计算初始状态概率\n",
    "                    Count_dic[line_state[0]] += 1   #记录每一个状态的出现次数\n",
    "                else:\n",
    "                    A_dic[line_state[i-1]][line_state[i]] += 1    #用于计算转移概率\n",
    "                    Count_dic[line_state[i]] += 1\n",
    "                    if word_list[i] not in B_dic[line_state[i]]:\n",
    "                        B_dic[line_state[i]][word_list[i]] = 0.0\n",
    "                    else:\n",
    "                        B_dic[line_state[i]][word_list[i]] += 1   #用于计算发射概率\n",
    "                        \n",
    "    Output()\n",
    "    ifp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "len(word_set) = 3728 \n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始测试\n",
    "def load_model(f_name):\n",
    "    ifp = open(f_name, 'rb')\n",
    "    return eval(ifp.read())  #eval参数是一个字符串, 可以把这个字符串当成表达式来求值,\n",
    "\n",
    "prob_start = load_model(PROB_START)\n",
    "prob_trans = load_model(PROB_EMIT)\n",
    "prob_emit = load_model(PROB_TRANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi(obs, states, start_p, trans_p, emit_p):  #维特比算法（一种递归算法）\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "    for y in states:   #初始值\n",
    "        V[0][y] = start_p[y] * emit_p[y].get(obs[0],0)   #在位置0，以y状态为末尾的状态序列的最大概率 \n",
    "        path[y] = [y]\n",
    "        print (\"V[0][y]: \",V[0][y])\n",
    "        print (\"path[y]: \",path[y])\n",
    "    for t in range(1,len(obs)):#华字进来\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    "        for y in states:      #从y0 -> y状态的递归 B  初始概率V[t-1][y0]*转换概率*这个词作为y的概率\n",
    "            tmp = [(V[t-1][y0] * trans_p[y0].get(y,0) * emit_p[y].get(obs[t],0) ,y0) for y0 in states if V[t-1][y0]>=0]\n",
    "            (prob, state) = max(tmp)\n",
    "            V[t][y] =prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "        path = newpath  #记录状态序列\n",
    "        print (\"V[t][y]: \",V[t])\n",
    "        print (\"path: \",path)\n",
    "    (prob, state) = max([(V[len(obs) - 1][y], y) for y in states])  #在最后一个位置，以y状态为末尾的状态序列的最大概率\n",
    "    print (\"prob: \",prob)\n",
    "    print (\"state: \",state)\n",
    "    return (prob, path[state])  #返回概率和状态序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(sentence):\n",
    "    prob, pos_list =  viterbi(sentence,('B','M','E','S'), prob_start, prob_trans, prob_emit)\n",
    "    return (prob,pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V[0][y]:  0.0\n",
      "path[y]:  ['B']\n",
      "V[0][y]:  0.0\n",
      "path[y]:  ['M']\n",
      "V[0][y]:  0.0\n",
      "path[y]:  ['E']\n",
      "V[0][y]:  0.0\n",
      "path[y]:  ['S']\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'B'], 'M': ['S', 'M'], 'E': ['S', 'E'], 'S': ['S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'B'], 'M': ['S', 'S', 'M'], 'E': ['S', 'S', 'E'], 'S': ['S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "V[t][y]:  {'B': 0.0, 'M': 0.0, 'E': 0.0, 'S': 0.0}\n",
      "path:  {'B': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B'], 'M': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'M'], 'E': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E'], 'S': ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']}\n",
      "prob:  0.0\n",
      "state:  S\n",
      "中华人民共和国成立了 北风网\n",
      "0.0\n",
      "['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "test_str = \"中华人民共和国成立了 北风网\"\n",
    "prob,pos_list = cut(test_str)\n",
    "print(test_str)\n",
    "print(prob)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
